{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\Engr Course\\VSCode\\ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "from timeseires.utils.to_split import to_split\n",
    "from timeseires.utils.multivariate_multi_step import multivariate_multi_step\n",
    "from timeseires.utils.multivariate_single_step import multivariate_single_step\n",
    "from timeseires.utils.univariate_multi_step import univariate_multi_step\n",
    "from timeseires.utils.univariate_single_step import univariate_single_step\n",
    "from timeseires.utils.CosineAnnealingLRS import CosineAnnealingLRS\n",
    "from timeseires.callbacks.EpochCheckpoint import EpochCheckpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D,TimeDistributed\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,MaxPooling1D,Concatenate,AveragePooling1D, GlobalMaxPooling1D, Input, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "import pandas as pd\n",
    "import time, pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Reshape, Lambda\n",
    "from tensorflow.keras.layers import Layer, Flatten, LeakyReLU, concatenate, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookback = 24\n",
    "model = None\n",
    "start_epoch = 0\n",
    "time_steps=24\n",
    "num_features=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn():\n",
    "    input_data = Input(shape=(time_steps, num_features))\n",
    "    rnn_layer1 = SimpleRNN(8, return_sequences=True)(input_data)\n",
    "    rnn_layer2 = SimpleRNN(20)(rnn_layer1)\n",
    "    x = Flatten()(rnn_layer2)\n",
    "    output_data = Dense(1)(x)\n",
    "    model = Model(input_data, output_data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m21\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_8 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_9 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m580\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">841</span> (3.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m841\u001b[0m (3.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">841</span> (3.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m841\u001b[0m (3.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_rnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "OUTPUT_PATH = r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\checkpoint\\ML Lab\\lab9'\n",
    "#FIG_PATH = os.path.sep.join([OUTPUT_PATH,\"\\history.png\"])\n",
    "#JSON_PATH = os.path.sep.join([OUTPUT_PATH,\"\\history.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochCheckpoint = ModelCheckpoint(checkpoints,\n",
    "                             monitor=\"val_loss\",\n",
    "                             save_best_only=True, \n",
    "                             verbose=1)\n",
    "#TrainingMonitor1=TrainingMonitor(FIG_PATH, jsonPath=JSON_PATH, startAt=start_epoch)\n",
    "\n",
    "# construct the set of callbacks\n",
    "callbacks = [EpochCheckpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model =create_rnn()\n",
    "opt = Adam(1e-3)\n",
    "model.compile(loss= 'mae', optimizer=opt, metrics=[\"mae\", \"mape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Engr Course\\VSCode\\ML\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((84907, 21), (24259, 21), (12130, 21))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path_dataset =r'C:\\Users\\swiss\\Desktop\\ML\\Lab 7'\n",
    "path_tr = os.path.join(path_dataset, 'AEP_train.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.iloc[:].values\n",
    "path_v = os.path.join(path_dataset, 'AEP_validation.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.iloc[:].values \n",
    "path_te = os.path.join(path_dataset, 'AEP_test.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.iloc[:].values \n",
    "\n",
    "path_scaler = os.path.join(path_dataset, 'AEP_Scaler.pkl')\n",
    "scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=24\n",
    "num_features=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed 0.8496363162994385 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=1)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=1)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=1)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0140 - mae: 0.0140 - mape: 240.5564\n",
      "Epoch 1: val_loss improved from 0.01480 to 0.01355, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0001-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 18ms/step - loss: 0.0140 - mae: 0.0140 - mape: 240.5412 - val_loss: 0.0136 - val_mae: 0.0136 - val_mape: 7.2530\n",
      "Epoch 2/10\n",
      "\u001b[1m2649/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0132 - mae: 0.0132 - mape: 18.7503\n",
      "Epoch 2: val_loss did not improve from 0.01355\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - loss: 0.0132 - mae: 0.0132 - mape: 19.0685 - val_loss: 0.0138 - val_mae: 0.0138 - val_mape: 5.9631\n",
      "Epoch 3/10\n",
      "\u001b[1m2651/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0127 - mae: 0.0127 - mape: 48.1553\n",
      "Epoch 3: val_loss improved from 0.01355 to 0.01127, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0003-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - loss: 0.0127 - mae: 0.0127 - mape: 48.3383 - val_loss: 0.0113 - val_mae: 0.0113 - val_mape: 4.9494\n",
      "Epoch 4/10\n",
      "\u001b[1m2651/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0122 - mae: 0.0122 - mape: 92.5776\n",
      "Epoch 4: val_loss did not improve from 0.01127\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0122 - mape: 92.6474 - val_loss: 0.0114 - val_mae: 0.0114 - val_mape: 5.8467\n",
      "Epoch 5/10\n",
      "\u001b[1m2648/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0116 - mae: 0.0116 - mape: 29.1342\n",
      "Epoch 5: val_loss improved from 0.01127 to 0.01025, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0005-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 0.0116 - mae: 0.0116 - mape: 29.1182 - val_loss: 0.0103 - val_mae: 0.0103 - val_mape: 5.1409\n",
      "Epoch 6/10\n",
      "\u001b[1m2652/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0111 - mae: 0.0111 - mape: 379.4239\n",
      "Epoch 6: val_loss improved from 0.01025 to 0.00981, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0006-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - loss: 0.0111 - mae: 0.0111 - mape: 379.3795 - val_loss: 0.0098 - val_mae: 0.0098 - val_mape: 4.6285\n",
      "Epoch 7/10\n",
      "\u001b[1m2651/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0107 - mae: 0.0107 - mape: 61.1159\n",
      "Epoch 7: val_loss did not improve from 0.00981\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - loss: 0.0107 - mae: 0.0107 - mape: 61.2730 - val_loss: 0.0102 - val_mae: 0.0102 - val_mape: 5.0893\n",
      "Epoch 8/10\n",
      "\u001b[1m2652/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0103 - mae: 0.0103 - mape: 730.6844\n",
      "Epoch 8: val_loss improved from 0.00981 to 0.00941, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0008-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - loss: 0.0103 - mae: 0.0103 - mape: 730.4013 - val_loss: 0.0094 - val_mae: 0.0094 - val_mape: 5.0358\n",
      "Epoch 9/10\n",
      "\u001b[1m2650/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0101 - mae: 0.0101 - mape: 65.2526\n",
      "Epoch 9: val_loss did not improve from 0.00941\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 0.0101 - mae: 0.0101 - mape: 65.2546 - val_loss: 0.0100 - val_mae: 0.0100 - val_mape: 4.4611\n",
      "Epoch 10/10\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0098 - mape: 29.7744\n",
      "Epoch 10: val_loss did not improve from 0.00941\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 0.0098 - mae: 0.0098 - mape: 29.8360 - val_loss: 0.0128 - val_mae: 0.0128 - val_mape: 5.7478\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = 1 #0\n",
    "batch_size = 32\n",
    "History = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        batch_size=batch_size,   \n",
    "                        epochs = epochs, \n",
    "                        validation_data = (validation_X,validation_y),\n",
    "                        callbacks = callbacks, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
      "Mean Absolute Error (MAE):        144.53\n",
      "Median Absolute Error (MedAE):    116.64\n",
      "Mean Squared Error (MSE):         35332.28\n",
      "Root Mean Squared Error (RMSE):   187.97\n",
      "Mean Absolute Percentage Error (MAPE):   1.00 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.80 %\n",
      "\n",
      "Shapes:\n",
      "y_test_unscaled: (12105, 1)\n",
      "y_pred:          (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the model (avoid compile errors by setting compile=False if needed)\n",
    "model = load_model(r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0008-loss0.01.h5', compile=False)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = model.predict(test_X)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "\n",
    "# Metrics Calculation\n",
    "MAE = mean_absolute_error(y_test_unscaled, y_pred)\n",
    "MEDAE = median_absolute_error(y_test_unscaled, y_pred)\n",
    "MSE = mean_squared_error(y_test_unscaled, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "# Safe MAPE and MDAPE (handle division by zero)\n",
    "epsilon = 1e-10\n",
    "denominator = np.where(np.abs(y_test_unscaled) < epsilon, epsilon, y_test_unscaled)\n",
    "MAPE = np.mean(np.abs((y_test_unscaled - y_pred) / denominator)) * 100\n",
    "MDAPE = np.median(np.abs((y_test_unscaled - y_pred) / denominator)) * 100\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean Absolute Error (MAE):        {MAE:.2f}\")\n",
    "print(f\"Median Absolute Error (MedAE):    {MEDAE:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE):         {MSE:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):   {RMSE:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE):   {MAPE:.2f} %\")\n",
    "print(f\"Median Absolute Percentage Error (MDAPE): {MDAPE:.2f} %\")\n",
    "\n",
    "# Shape Check\n",
    "print(\"\\nShapes:\")\n",
    "print(f\"y_test_unscaled: {y_test_unscaled.shape}\")\n",
    "print(f\"y_pred:          {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "model1=r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E1-cp-0008-loss0.01.h5'\n",
    "start_epoch= 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerConsumptionModel:\n",
    "    @staticmethod\n",
    "    def build(time_steps, num_features, reg):\n",
    "        # define your Keras model here\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MeanAbsoluteError\n",
    "from keras.metrics import MeanAbsolutePercentageError\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to model checkpoint\n",
    "checkpoints = r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "\n",
    "# Define callbacks\n",
    "EpochCheckpoint1 = ModelCheckpoint(\n",
    "    checkpoints,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "callbacks = [EpochCheckpoint1]\n",
    "\n",
    "# If checkpoint doesn't exist, compile a new model\n",
    "if not os.path.exists(checkpoints):\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model = PowerConsumptionModel.build(time_steps=24, num_features=21, reg=0.0005)\n",
    "    opt = Adam(1e-3)\n",
    "    model.compile(loss='mae', optimizer=opt, metrics=[\"mae\", \"mape\"])\n",
    "else:\n",
    "    # Load the model\n",
    "    print(f\"[INFO] loading model from {checkpoints}...\")\n",
    "    custom_objects = {\n",
    "        'mae': MeanAbsoluteError(),\n",
    "        'mape': MeanAbsolutePercentageError()\n",
    "    }\n",
    "    model = load_model(checkpoints, custom_objects=custom_objects)\n",
    "\n",
    "    # Update learning rate\n",
    "    old_lr = K.get_value(model.optimizer.lr)\n",
    "    print(f\"[INFO] old learning rate: {old_lr}\")\n",
    "    K.set_value(model.optimizer.lr, 1e-4)\n",
    "    print(f\"[INFO] new learning rate: {K.get_value(model.optimizer.lr)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0094 - mae: 0.0094 - mape: 247.3583\n",
      "Epoch 1: val_loss improved from inf to 0.00884, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-0001-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 16ms/step - loss: 0.0094 - mae: 0.0094 - mape: 247.3484 - val_loss: 0.0088 - val_mae: 0.0088 - val_mape: 4.6011\n",
      "Epoch 2/10\n",
      "\u001b[1m2651/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0091 - mae: 0.0091 - mape: 18.6007\n",
      "Epoch 2: val_loss did not improve from 0.00884\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 20ms/step - loss: 0.0091 - mae: 0.0091 - mape: 18.9146 - val_loss: 0.0112 - val_mae: 0.0112 - val_mape: 6.0932\n",
      "Epoch 3/10\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0089 - mae: 0.0089 - mape: 181.7989\n",
      "Epoch 3: val_loss did not improve from 0.00884\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - loss: 0.0089 - mae: 0.0089 - mape: 181.7949 - val_loss: 0.0093 - val_mae: 0.0093 - val_mape: 4.8249\n",
      "Epoch 4/10\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0087 - mae: 0.0087 - mape: 41.7324\n",
      "Epoch 4: val_loss did not improve from 0.00884\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - loss: 0.0087 - mae: 0.0087 - mape: 41.7848 - val_loss: 0.0100 - val_mae: 0.0100 - val_mape: 4.6680\n",
      "Epoch 5/10\n",
      "\u001b[1m2650/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0087 - mae: 0.0087 - mape: 42.7055\n",
      "Epoch 5: val_loss improved from 0.00884 to 0.00876, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-0005-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - loss: 0.0087 - mae: 0.0087 - mape: 42.6905 - val_loss: 0.0088 - val_mae: 0.0088 - val_mape: 3.9798\n",
      "Epoch 6/10\n",
      "\u001b[1m2648/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0086 - mae: 0.0086 - mape: 295.6519\n",
      "Epoch 6: val_loss did not improve from 0.00876\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - loss: 0.0086 - mae: 0.0086 - mape: 295.4460 - val_loss: 0.0091 - val_mae: 0.0091 - val_mape: 4.6845\n",
      "Epoch 7/10\n",
      "\u001b[1m2649/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0085 - mae: 0.0085 - mape: 478.6481\n",
      "Epoch 7: val_loss improved from 0.00876 to 0.00820, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-0007-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - loss: 0.0085 - mae: 0.0085 - mape: 478.1693 - val_loss: 0.0082 - val_mae: 0.0082 - val_mape: 3.7267\n",
      "Epoch 8/10\n",
      "\u001b[1m2649/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0085 - mae: 0.0085 - mape: 25.5437\n",
      "Epoch 8: val_loss improved from 0.00820 to 0.00793, saving model to C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-0008-loss0.01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - loss: 0.0085 - mae: 0.0085 - mape: 25.7859 - val_loss: 0.0079 - val_mae: 0.0079 - val_mape: 3.4656\n",
      "Epoch 9/10\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0084 - mae: 0.0084 - mape: 100.6684\n",
      "Epoch 9: val_loss did not improve from 0.00793\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - loss: 0.0084 - mae: 0.0084 - mape: 100.7136 - val_loss: 0.0139 - val_mae: 0.0139 - val_mape: 6.9336\n",
      "Epoch 10/10\n",
      "\u001b[1m2652/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - mae: 0.0083 - mape: 47.3594\n",
      "Epoch 10: val_loss did not improve from 0.00793\n",
      "\u001b[1m2653/2653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 0.0083 - mae: 0.0083 - mape: 47.4528 - val_loss: 0.0083 - val_mae: 0.0083 - val_mape: 3.8813\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = 1 #0\n",
    "batch_size = 32\n",
    "History = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        batch_size=batch_size,   \n",
    "                        epochs = epochs, \n",
    "                        validation_data = (validation_X,validation_y),\n",
    "                        callbacks=callbacks,\n",
    "                        verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "Mean Absolute Error (MAE):        126.62\n",
      "Median Absolute Error (MedAE):    102.83\n",
      "Mean Squared Error (MSE):         26885.55\n",
      "Root Mean Squared Error (RMSE):   163.97\n",
      "Mean Absolute Percentage Error (MAPE):   0.87 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.71 %\n",
      "\n",
      "Shapes:\n",
      "y_test_unscaled: (12105, 1)\n",
      "y_pred:          (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the model (avoid compile errors by setting compile=False if needed)\n",
    "model = load_model(r'C:\\Users\\swiss\\Desktop\\ML\\Lab 9\\E2-cp-0008-loss0.01.h5', compile=False)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = model.predict(test_X)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "\n",
    "# Metrics Calculation\n",
    "MAE = mean_absolute_error(y_test_unscaled, y_pred)\n",
    "MEDAE = median_absolute_error(y_test_unscaled, y_pred)\n",
    "MSE = mean_squared_error(y_test_unscaled, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "# Safe MAPE and MDAPE (handle division by zero)\n",
    "epsilon = 1e-10\n",
    "denominator = np.where(np.abs(y_test_unscaled) < epsilon, epsilon, y_test_unscaled)\n",
    "MAPE = np.mean(np.abs((y_test_unscaled - y_pred) / denominator)) * 100\n",
    "MDAPE = np.median(np.abs((y_test_unscaled - y_pred) / denominator)) * 100\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean Absolute Error (MAE):        {MAE:.2f}\")\n",
    "print(f\"Median Absolute Error (MedAE):    {MEDAE:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE):         {MSE:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):   {RMSE:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE):   {MAPE:.2f} %\")\n",
    "print(f\"Median Absolute Percentage Error (MDAPE): {MDAPE:.2f} %\")\n",
    "\n",
    "# Shape Check\n",
    "print(\"\\nShapes:\")\n",
    "print(f\"y_test_unscaled: {y_test_unscaled.shape}\")\n",
    "print(f\"y_pred:          {y_pred.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
